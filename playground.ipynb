{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2762184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ndrw1221/miniconda3/envs/finetune-stable-audio-open/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]/home/ndrw1221/miniconda3/envs/finetune-stable-audio-open/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [00:04<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableAudioPipeline\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = StableAudioPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-audio-open-1.0\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ebd3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vae', 'text_encoder', 'projection_model', 'tokenizer', 'transformer', 'scheduler'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.components.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b837d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = pipe.transformer\n",
    "transformer.requires_grad_(False)\n",
    "for block in transformer.transformer_blocks:\n",
    "    block.attn2.to_k.weight.requires_grad = True\n",
    "    block.attn2.to_v.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a78426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_blocks.0.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.0.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.1.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.1.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.2.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.2.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.3.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.3.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.4.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.4.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.5.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.5.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.6.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.6.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.7.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.7.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.8.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.8.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.9.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.9.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.10.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.10.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.11.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.11.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.12.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.12.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.13.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.13.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.14.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.14.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.15.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.15.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.16.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.16.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.17.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.17.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.18.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.18.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.19.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.19.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.20.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.20.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.21.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.21.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.22.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.22.attn2.to_v.weight torch.Size([768, 768])\n",
      "transformer_blocks.23.attn2.to_k.weight torch.Size([768, 768])\n",
      "transformer_blocks.23.attn2.to_v.weight torch.Size([768, 768])\n"
     ]
    }
   ],
   "source": [
    "for name, param in transformer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a7e59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StableAudioProjectionModel(\n",
       "  (text_projection): Identity()\n",
       "  (start_number_conditioner): StableAudioNumberConditioner(\n",
       "    (time_positional_embedding): Sequential(\n",
       "      (0): StableAudioPositionalEmbedding()\n",
       "      (1): Linear(in_features=257, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (end_number_conditioner): StableAudioNumberConditioner(\n",
       "    (time_positional_embedding): Sequential(\n",
       "      (0): StableAudioPositionalEmbedding()\n",
       "      (1): Linear(in_features=257, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.vae.requires_grad_(False)\n",
    "pipe.text_encoder.requires_grad_(False)\n",
    "pipe.projection_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa62dd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_blocks.0.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.0.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.0.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.0.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.0.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.0.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.0.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.0.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.0.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.0.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.0.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.0.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.0.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.0.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.0.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.0.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.1.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.1.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.1.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.1.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.1.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.1.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.1.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.1.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.1.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.1.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.1.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.1.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.1.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.1.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.1.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.1.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.2.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.2.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.2.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.2.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.2.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.2.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.2.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.2.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.2.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.2.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.2.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.2.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.2.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.2.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.2.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.2.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.3.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.3.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.3.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.3.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.3.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.3.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.3.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.3.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.3.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.3.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.3.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.3.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.3.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.3.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.3.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.3.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.4.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.4.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.4.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.4.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.4.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.4.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.4.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.4.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.4.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.4.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.4.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.4.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.4.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.4.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.4.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.4.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.5.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.5.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.5.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.5.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.5.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.5.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.5.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.5.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.5.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.5.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.5.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.5.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.5.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.5.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.5.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.5.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.6.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.6.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.6.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.6.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.6.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.6.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.6.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.6.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.6.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.6.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.6.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.6.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.6.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.6.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.6.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.6.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.7.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.7.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.7.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.7.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.7.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.7.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.7.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.7.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.7.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.7.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.7.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.7.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.7.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.7.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.7.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.7.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.8.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.8.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.8.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.8.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.8.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.8.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.8.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.8.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.8.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.8.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.8.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.8.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.8.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.8.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.8.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.8.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.9.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.9.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.9.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.9.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.9.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.9.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.9.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.9.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.9.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.9.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.9.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.9.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.9.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.9.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.9.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.9.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.10.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.10.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.10.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.10.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.10.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.10.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.10.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.10.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.10.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.10.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.10.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.10.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.10.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.10.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.10.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.10.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.11.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.11.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.11.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.11.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.11.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.11.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.11.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.11.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.11.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.11.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.11.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.11.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.11.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.11.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.11.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.11.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.12.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.12.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.12.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.12.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.12.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.12.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.12.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.12.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.12.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.12.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.12.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.12.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.12.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.12.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.12.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.12.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.13.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.13.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.13.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.13.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.13.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.13.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.13.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.13.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.13.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.13.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.13.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.13.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.13.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.13.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.13.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.13.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.14.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.14.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.14.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.14.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.14.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.14.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.14.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.14.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.14.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.14.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.14.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.14.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.14.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.14.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.14.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.14.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.15.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.15.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.15.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.15.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.15.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.15.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.15.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.15.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.15.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.15.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.15.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.15.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.15.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.15.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.15.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.15.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.16.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.16.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.16.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.16.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.16.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.16.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.16.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.16.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.16.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.16.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.16.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.16.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.16.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.16.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.16.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.16.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.17.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.17.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.17.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.17.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.17.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.17.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.17.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.17.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.17.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.17.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.17.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.17.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.17.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.17.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.17.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.17.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.18.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.18.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.18.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.18.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.18.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.18.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.18.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.18.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.18.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.18.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.18.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.18.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.18.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.18.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.18.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.18.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.19.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.19.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.19.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.19.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.19.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.19.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.19.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.19.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.19.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.19.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.19.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.19.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.19.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.19.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.19.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.19.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.20.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.20.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.20.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.20.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.20.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.20.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.20.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.20.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.20.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.20.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.20.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.20.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.20.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.20.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.20.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.20.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.21.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.21.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.21.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.21.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.21.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.21.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.21.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.21.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.21.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.21.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.21.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.21.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.21.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.21.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.21.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.21.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.22.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.22.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.22.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.22.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.22.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.22.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.22.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.22.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.22.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.22.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.22.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.22.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.22.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.22.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.22.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.22.attn2.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.23.attn1.to_q.lora_A.default.weight\n",
      "transformer_blocks.23.attn1.to_q.lora_B.default.weight\n",
      "transformer_blocks.23.attn1.to_k.lora_A.default.weight\n",
      "transformer_blocks.23.attn1.to_k.lora_B.default.weight\n",
      "transformer_blocks.23.attn1.to_v.lora_A.default.weight\n",
      "transformer_blocks.23.attn1.to_v.lora_B.default.weight\n",
      "transformer_blocks.23.attn1.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.23.attn1.to_out.0.lora_B.default.weight\n",
      "transformer_blocks.23.attn2.to_q.lora_A.default.weight\n",
      "transformer_blocks.23.attn2.to_q.lora_B.default.weight\n",
      "transformer_blocks.23.attn2.to_k.lora_A.default.weight\n",
      "transformer_blocks.23.attn2.to_k.lora_B.default.weight\n",
      "transformer_blocks.23.attn2.to_v.lora_A.default.weight\n",
      "transformer_blocks.23.attn2.to_v.lora_B.default.weight\n",
      "transformer_blocks.23.attn2.to_out.0.lora_A.default.weight\n",
      "transformer_blocks.23.attn2.to_out.0.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in pipe.transformer.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7f14ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "# transformer 加上 LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=4,  # bottleneck rank\n",
    "    lora_alpha=16,  # scaling factor\n",
    "    target_modules=[\n",
    "        \"to_q\",\n",
    "        \"to_k\",\n",
    "        \"to_v\",\n",
    "        \"to_out.0\",\n",
    "    ],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# 取得 transformer 模型，加入 LoRA\n",
    "transformer_with_lora = get_peft_model(pipe.transformer, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcc900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.cross_attention_proj.0.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.cross_attention_proj.2.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.global_proj.0.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.global_proj.2.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.postprocess_conv.weight: shape=(64, 64, 1), dtype=torch.float16\n",
      "base_model.model.preprocess_conv.weight: shape=(64, 64, 1), dtype=torch.float16\n",
      "base_model.model.proj_in.weight: shape=(1536, 64), dtype=torch.float16\n",
      "base_model.model.proj_out.weight: shape=(64, 1536), dtype=torch.float16\n",
      "base_model.model.time_proj.weight: shape=(128,), dtype=torch.float16\n",
      "base_model.model.timestep_proj.0.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.timestep_proj.0.weight: shape=(1536, 256), dtype=torch.float16\n",
      "base_model.model.timestep_proj.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.timestep_proj.2.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.0.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.0.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.1.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.1.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.10.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.10.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.11.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.11.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.12.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.12.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.13.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.13.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.14.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.14.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.15.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.15.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.16.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.16.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.17.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.17.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.18.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.18.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.19.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.19.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.2.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.2.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.20.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.20.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.21.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.21.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.22.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.22.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.23.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.23.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.3.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.3.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.4.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.4.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.5.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.5.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.6.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.6.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.7.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.7.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.8.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.8.norm3.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn1.to_k.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn1.to_k.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_k.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn1.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn1.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_v.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn1.to_v.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn1.to_v.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_k.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn2.to_k.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_k.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_out.0.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn2.to_out.0.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_out.0.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_q.base_layer.weight: shape=(1536, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn2.to_q.lora_A.default.weight: shape=(16, 1536), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_q.lora_B.default.weight: shape=(1536, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_v.base_layer.weight: shape=(768, 768), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.attn2.to_v.lora_A.default.weight: shape=(16, 768), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.attn2.to_v.lora_B.default.weight: shape=(768, 16), dtype=torch.float32\n",
      "base_model.model.transformer_blocks.9.ff.net.0.proj.bias: shape=(12288,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.ff.net.0.proj.weight: shape=(12288, 1536), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.ff.net.2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.ff.net.2.weight: shape=(1536, 6144), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm1.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm1.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm2.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm2.weight: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm3.bias: shape=(1536,), dtype=torch.float16\n",
      "base_model.model.transformer_blocks.9.norm3.weight: shape=(1536,), dtype=torch.float16\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "# 載入 safetensors 檔案\n",
    "tensor_dict = load_file(\n",
    "    \"/mnt/gestalt/home/ndrw1221/sao_pili-output/output/run_2025-05-23 03:08:48/checkpoint-5000/model.safetensors\"\n",
    ")\n",
    "\n",
    "# 印出有哪些 tensor、各自的 shape 和 dtype\n",
    "for key, tensor in tensor_dict.items():\n",
    "    print(f\"{key}: shape={tuple(tensor.shape)}, dtype={tensor.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-stable-audio-open",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
